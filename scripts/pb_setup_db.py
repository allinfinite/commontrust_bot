#!/usr/bin/env python3
"""
Idempotent PocketBase DB setup for this project.

Creates the collections defined in pb_schema.json on the target PocketBase instance.
By default, it only creates missing collections (no destructive updates).

Prereqs:
- .env.local contains POCKETBASE_URL and POCKETBASE_ADMIN_TOKEN (generated by pb_create_admin_token.py)

Usage:
  python3 scripts/pb_setup_db.py
  python3 scripts/pb_setup_db.py --dry-run
  python3 scripts/pb_setup_db.py --update-existing   # patch existing collections too (use carefully)
"""

from __future__ import annotations

import argparse
import json
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import httpx
from dotenv import load_dotenv


class PBSetupError(Exception):
    pass


def _load_env() -> None:
    # Prefer .env.local then .env (matches commontrust_bot/config.py behavior).
    load_dotenv(".env.local", override=False)
    load_dotenv(".env", override=False)


def _must_env(name: str) -> str:
    val = os.environ.get(name)
    if not val or not val.strip():
        raise PBSetupError(f"Missing required env var: {name}")
    return val.strip()


@dataclass(frozen=True)
class PBConn:
    base_url: str
    token: str

    @property
    def headers(self) -> dict[str, str]:
        # PocketBase expects the raw token in the Authorization header.
        return {"Authorization": self.token}


def _read_schema(path: Path) -> list[dict[str, Any]]:
    data = json.loads(path.read_text(encoding="utf-8"))
    if not isinstance(data, list):
        raise PBSetupError(f"{path} must be a JSON list of collections")
    for c in data:
        if not isinstance(c, dict) or "name" not in c:
            raise PBSetupError(f"Invalid collection in {path}: {c!r}")
    return data


def _pb_field(field: dict[str, Any], name_to_id: dict[str, str]) -> dict[str, Any]:
    ftype = field["type"]
    # PocketBase uses "date" for date-time values; our schema calls it "datetime".
    pb_type = "date" if ftype == "datetime" else ftype
    out: dict[str, Any] = {
        "name": field["name"],
        "type": pb_type,
        "required": bool(field.get("required", False)),
        "unique": bool(field.get("unique", False)),
    }

    # PocketBase v0.23+ uses flat field options (no nested "options" object).
    if pb_type == "text":
        out.update({"min": None, "max": None, "pattern": "", "autogeneratePattern": ""})
    elif pb_type == "number":
        out.update({"min": None, "max": None, "noDecimal": False})
    elif pb_type == "bool":
        pass
    elif pb_type == "date":
        out.update({"min": "", "max": ""})
    elif pb_type == "select":
        values = field.get("values")
        if not isinstance(values, list) or not values:
            raise PBSetupError(f"select field missing values: {field!r}")
        out.update({"maxSelect": 1, "values": values})
    elif pb_type == "relation":
        target = field.get("collectionId")
        if not isinstance(target, str) or not target:
            raise PBSetupError(f"relation field missing collectionId: {field!r}")
        if target not in name_to_id:
            raise PBSetupError(f"relation target collection not found yet: {target}")
        out.update(
            {
                "collectionId": name_to_id[target],
                "cascadeDelete": bool(field.get("cascadeDelete", False)),
                "minSelect": field.get("minSelect", None),
                "maxSelect": field.get("maxSelect", 1),
                "displayFields": [],
            }
        )
    elif pb_type == "autodate":
        # Automatically managed timestamps (useful for reliable sorting in some PocketBase builds
        # where the implicit system "created"/"updated" are not sortable).
        out.update(
            {
                "onCreate": bool(field.get("onCreate", True)),
                "onUpdate": bool(field.get("onUpdate", False)),
            }
        )
    else:
        raise PBSetupError(f"Unsupported field type in pb_schema.json: {ftype}")

    return out


def _deps_for_collection(coll: dict[str, Any]) -> set[str]:
    deps: set[str] = set()
    for f in coll.get("schema", []):
        if isinstance(f, dict) and f.get("type") == "relation":
            tgt = f.get("collectionId")
            if isinstance(tgt, str) and tgt:
                deps.add(tgt)
    return deps


def _toposort(collections: list[dict[str, Any]]) -> list[dict[str, Any]]:
    by_name = {c["name"]: c for c in collections}
    deps = {name: _deps_for_collection(c) for name, c in by_name.items()}
    # Keep only deps that are in-scope (ignore system collections like "users").
    deps = {n: {d for d in ds if d in by_name} for n, ds in deps.items()}

    ordered: list[dict[str, Any]] = []
    remaining = set(by_name.keys())
    while remaining:
        ready = sorted([n for n in remaining if not deps[n]])
        if not ready:
            cycle = ", ".join(sorted(remaining))
            raise PBSetupError(f"Schema has cyclic/unsatisfied dependencies among: {cycle}")
        for n in ready:
            ordered.append(by_name[n])
            remaining.remove(n)
            for m in remaining:
                deps[m].discard(n)
    return ordered


def _pb_get_collections(client: httpx.Client, conn: PBConn) -> dict[str, dict[str, Any]]:
    r = client.get(f"{conn.base_url}/api/collections", headers=conn.headers, params={"perPage": 200})
    if r.status_code != 200:
        raise PBSetupError(f"Failed to list collections ({r.status_code}): {r.text}")
    data = r.json()
    items = data.get("items", [])
    out: dict[str, dict[str, Any]] = {}
    for c in items:
        name = c.get("name")
        if isinstance(name, str):
            out[name] = c
    return out


def _pb_create_collection(
    client: httpx.Client,
    conn: PBConn,
    coll: dict[str, Any],
    name_to_id: dict[str, str],
    include_indexes: bool,
    dry_run: bool,
) -> dict[str, Any]:
    payload: dict[str, Any] = {
        "name": coll["name"],
        "type": coll.get("type", "base"),
        "fields": [_pb_field(f, name_to_id) for f in coll.get("schema", [])],
        # WARNING: PocketBase stores field values in the 'data' JSON column and index expressions
        # must reference json_extract(...). The pb_schema.json indexes are legacy and may fail.
        "indexes": coll.get("indexes", []) if include_indexes else [],
    }

    if dry_run:
        print(f"[dry-run] would create collection: {coll['name']}")
        return {"id": "<dry-run>", "name": coll["name"]}

    r = client.post(f"{conn.base_url}/api/collections", headers=conn.headers, json=payload)
    if r.status_code != 200:
        raise PBSetupError(f"Failed to create collection {coll['name']} ({r.status_code}): {r.text}")
    return r.json()


def _pb_update_collection(
    client: httpx.Client,
    conn: PBConn,
    coll_id: str,
    coll: dict[str, Any],
    name_to_id: dict[str, str],
    include_indexes: bool,
    dry_run: bool,
) -> None:
    payload: dict[str, Any] = {
        "name": coll["name"],
        "type": coll.get("type", "base"),
        "fields": [_pb_field(f, name_to_id) for f in coll.get("schema", [])],
        "indexes": coll.get("indexes", []) if include_indexes else [],
    }

    if dry_run:
        print(f"[dry-run] would update collection: {coll['name']}")
        return

    r = client.patch(f"{conn.base_url}/api/collections/{coll_id}", headers=conn.headers, json=payload)
    if r.status_code != 200:
        raise PBSetupError(f"Failed to update collection {coll['name']} ({r.status_code}): {r.text}")


def main() -> int:
    parser = argparse.ArgumentParser()
    parser.add_argument("--dry-run", action="store_true", help="Print actions without changing anything")
    parser.add_argument(
        "--update-existing",
        action="store_true",
        help="Patch existing collections to match pb_schema.json (non-destructive but can affect live data)",
    )
    parser.add_argument(
        "--with-indexes",
        action="store_true",
        help="Also apply indexes from pb_schema.json (may fail on newer PocketBase)",
    )
    args = parser.parse_args()

    _load_env()
    conn = PBConn(
        base_url=_must_env("POCKETBASE_URL").rstrip("/"),
        token=_must_env("POCKETBASE_ADMIN_TOKEN"),
    )

    schema_path = Path("pb_schema.json")
    desired = _toposort(_read_schema(schema_path))

    with httpx.Client(timeout=30.0) as client:
        existing = _pb_get_collections(client, conn)
        # Used for resolving relation targets while creating.
        name_to_id: dict[str, str] = {name: c["id"] for name, c in existing.items() if "id" in c}

        created = 0
        updated = 0

        for coll in desired:
            name = coll["name"]
            if name in existing:
                if args.update_existing:
                    _pb_update_collection(
                        client,
                        conn,
                        existing[name]["id"],
                        coll,
                        name_to_id,
                        args.with_indexes,
                        args.dry_run,
                    )
                    updated += 1
                else:
                    print(f"skip existing collection: {name}")
                continue

            if coll.get("indexes") and not args.with_indexes:
                print(f"note: skipping indexes for {name} (use --with-indexes to apply)")

            created_coll = _pb_create_collection(
                client, conn, coll, name_to_id, args.with_indexes, args.dry_run
            )
            created += 1
            # Update mapping so later relation fields can point at this ID.
            if isinstance(created_coll, dict) and "id" in created_coll:
                name_to_id[name] = created_coll["id"]

        print(f"done: created={created} updated={updated} dry_run={bool(args.dry_run)}")

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
